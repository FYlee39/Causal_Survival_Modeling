{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Benchmark test on SUPPORT",
   "id": "3089edadb72a1fc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import data set",
   "id": "1a750dcc05ebc0c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:22.686707Z",
     "start_time": "2025-06-24T20:51:22.624873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from auton_survival import datasets\n",
    "outcomes, features = datasets.load_support()"
   ],
   "id": "6ce0854996fff80a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocess data",
   "id": "5f02004bb2c61715"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:24.156775Z",
     "start_time": "2025-06-24T20:51:24.102920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auton_survival.preprocessing import Preprocessor\n",
    "\n",
    "cat_feats = ['sex', 'dzgroup', 'dzclass', 'income', 'race', 'ca']\n",
    "num_feats = ['age', 'num.co', 'meanbp', 'wblc', 'hrt', 'resp',\n",
    "             'temp', 'pafi', 'alb', 'bili', 'crea', 'sod', 'ph',\n",
    "             'glucose', 'bun', 'urine', 'adlp', 'adls']\n",
    "\n",
    "\n",
    "features = Preprocessor().fit_transform(features, cat_feats=cat_feats, num_feats=num_feats)\n",
    "\n",
    "\n",
    "horizons = [0.25, 0.5, 0.75]\n",
    "times = np.quantile(outcomes.time[outcomes.event==1], horizons).tolist()\n",
    "\n",
    "x, t, e = features.values, outcomes.time.values, outcomes.event.values\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "tr_size = int(n * 0.70)\n",
    "vl_size = int(n * 0.10)\n",
    "te_size = int(n * 0.20)\n",
    "\n",
    "x_train, x_test, x_val = x[:tr_size], x[-te_size:], x[tr_size:tr_size+vl_size]\n",
    "t_train, t_test, t_val = t[:tr_size], t[-te_size:], t[tr_size:tr_size+vl_size]\n",
    "e_train, e_test, e_val = e[:tr_size], e[-te_size:], e[tr_size:tr_size+vl_size]\n",
    "\n",
    "t = outcomes[\"time\"]\n",
    "e = outcomes[\"event\"]\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "quantiles = np.quantile(t[e == 1], quantiles)\n",
    "\n",
    "def dataframe_to_tensor(data):\n",
    "    \"\"\"Function that converts a pandas dataframe into a tensor\"\"\"\n",
    "    if isinstance(data, (pd.Series, pd.DataFrame)):\n",
    "        return data.to_numpy()\n",
    "    else:\n",
    "        return torch.from_numpy(data).float()\n",
    "\n",
    "x_val_tensor = dataframe_to_tensor(x_val)\n",
    "t_val_tensor = dataframe_to_tensor(t_val)\n",
    "e_val_tensor = dataframe_to_tensor(e_val)"
   ],
   "id": "7aaf7e3e6b9fd57",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:25.979900Z",
     "start_time": "2025-06-24T20:51:25.974916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = (x_train, t_train, e_train)\n",
    "val_data_tensor = (x_val_tensor, t_val_tensor, e_val_tensor)\n",
    "val_data = (x_val, t_val, e_val)\n",
    "test_data = (x_test, t_test, e_test)"
   ],
   "id": "a6f7b235b50ebfc0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DCM model",
   "id": "381635143fbd0a08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:27.309949Z",
     "start_time": "2025-06-24T20:51:27.303964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auton_survival.models.dcm import DeepCoxMixtures\n",
    "from auton_survival.models.dcm.dcm_utilities import test_step\n",
    "\n",
    "# hyperparameters according to the paper\n",
    "DCM_param_grid = {\"k\" : [3, 4, 6],\n",
    "                  \"learning_rate\" : [1e-3],\n",
    "                  \"layers\" : [[50], [100], [50, 50], [100, 100]],\n",
    "                  \"batch_size\": [128]\n",
    "                  }\n",
    "\n",
    "DCM_params = ParameterGrid(DCM_param_grid)"
   ],
   "id": "eefd45c66181587f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:28.652561Z",
     "start_time": "2025-06-24T20:51:28.637565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DCM_Wrapper(object):\n",
    "    def __init__(self, params_grid):\n",
    "        self.params_grid = params_grid\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, train_set, val_set):\n",
    "\n",
    "        x_train, t_train, e_train = train_set\n",
    "        x_val, t_val, e_val = val_set\n",
    "        x_val_tensor = dataframe_to_tensor(x_val)\n",
    "        t_val_tensor = dataframe_to_tensor(t_val)\n",
    "        e_val_tensor = dataframe_to_tensor(e_val)\n",
    "\n",
    "        models = []\n",
    "        for param in self.params_grid:\n",
    "            model = DeepCoxMixtures(k=param[\"k\"],\n",
    "                                    layers=param[\"layers\"])\n",
    "            # The fit method is called to train the model\n",
    "            model.fit(x_train, t_train, e_train,\n",
    "                      iters=100,\n",
    "                      learning_rate=param[\"learning_rate\"],\n",
    "                      batch_size=param[\"batch_size\"])\n",
    "\n",
    "            # store the performance on the validation set\n",
    "            breslow_splines = model.torch_model[1]\n",
    "            val_result = test_step(model.torch_model[0], x_val_tensor, t_val_tensor, e_val_tensor, breslow_splines)\n",
    "            models.append([[val_result, model]])\n",
    "\n",
    "        best_model = min(models)\n",
    "        self.model = best_model[0][1]\n",
    "\n",
    "    def predict(self, test_set):\n",
    "\n",
    "        x_test, t_test, e_test = test_set\n",
    "\n",
    "        out_survival = self.model.predict_survival(x_test, times)\n",
    "        out_risk = 1 - out_survival\n",
    "\n",
    "        return out_survival, out_risk\n"
   ],
   "id": "ac4e8e4734171cd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DSM model",
   "id": "549b2181f57a5f86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T20:51:30.573914Z",
     "start_time": "2025-06-24T20:51:30.567929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auton_survival.models.dsm import DeepSurvivalMachines\n",
    "\n",
    "DSM_param_grid = {\"distribution\": ['Weibull'],\n",
    "                  \"k\": [3, 4],\n",
    "                  \"layers\": [[], [50], [50, 50], [100], [100, 100]],\n",
    "                  \"batch_size\": [128, 256],\n",
    "                  \"learning_rate\": [ 1e-4, 1e-3],\n",
    "                  \"activation\": [\"SeLu\"]\n",
    "             }\n",
    "DSM_params = ParameterGrid(DSM_param_grid)"
   ],
   "id": "a8271acef2a37329",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:41:43.908287Z",
     "start_time": "2025-06-24T21:41:43.894325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DSM_Wrapper(object):\n",
    "    def __init__(self, params_grid):\n",
    "        self.params_grid = params_grid\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, train_set, val_set):\n",
    "\n",
    "        models = []\n",
    "        x_train, t_train, e_train = train_set\n",
    "        x_val, t_val, e_val = val_set\n",
    "        for param in self.params_grid:\n",
    "            model = DeepSurvivalMachines(k=param['k'],\n",
    "                                 distribution=param['distribution'],\n",
    "                                 layers=param['layers'])\n",
    "\n",
    "            model.fit(x_train, t_train, e_train, iters=100, learning_rate=param['learning_rate'])\n",
    "            models.append([model.compute_nll(x_val, t_val, e_val), model])\n",
    "\n",
    "        best_model_entry = min(models, key=lambda x: x[0])\n",
    "\n",
    "        # Extract the model\n",
    "        self.model = best_model_entry[1]\n",
    "\n",
    "    def predict(self, test_set):\n",
    "\n",
    "        x_test, t_test, e_test = test_set\n",
    "\n",
    "        out_survival = self.model.predict_survival(x_test, times)\n",
    "        out_risk = 1 - self.model.predict_risk(x_test, times)\n",
    "\n",
    "        return out_survival, out_risk\n"
   ],
   "id": "aeeb382e6aa2ddcc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Benchmark Function",
   "id": "9339cae5de43c68d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:41:38.914846Z",
     "start_time": "2025-06-24T21:41:38.890432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pickle\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "def benchmark_model(name, model_wrap, train_set, val_set, test_set):\n",
    "    result = {'Model': name}\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        model_wrap.fit(train_set=train_set, val_set=val_set)\n",
    "        result['Train Time'] = time.time() - start\n",
    "        print(\"Fit complete!\")\n",
    "\n",
    "        start = time.time()\n",
    "        survival, risk = model_wrap.predict(test_set)\n",
    "        result['Predict Time'] = time.time() - start\n",
    "        print(\"Predict complete!\")\n",
    "\n",
    "        cis = []\n",
    "        brs = []\n",
    "\n",
    "        et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                         dtype = [('e', bool), ('t', float)])\n",
    "        et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                         dtype = [('e', bool), ('t', float)])\n",
    "        et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "                         dtype = [('e', bool), ('t', float)])\n",
    "\n",
    "        for i, _ in enumerate(times):\n",
    "            cis.append(concordance_index_ipcw(et_train, et_test, risk[:, i], times[i])[0])\n",
    "\n",
    "        brs.append(brier_score(et_train, et_test, survival, times)[1])\n",
    "        roc_auc = []\n",
    "\n",
    "        for i, _ in enumerate(times):\n",
    "            roc_auc.append(cumulative_dynamic_auc(et_train, et_test, risk[:, i], times[i])[0])\n",
    "\n",
    "        for horizon in enumerate(horizons):\n",
    "            result[f\"{horizon[1]} quantile TD Concordance Index\"] = cis[horizon[0]]\n",
    "            result[f\"{horizon[1]} quantile Brier Score\"] = brs[0][horizon[0]]\n",
    "            result[f\"{horizon[1]} quantile ROC AUC\"] = roc_auc[horizon[0]][0]\n",
    "\n",
    "    except Exception as e:\n",
    "        result['Error'] = str(e)\n",
    "\n",
    "    return result\n"
   ],
   "id": "f1edfdce06c3612e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:54:46.685102Z",
     "start_time": "2025-06-24T21:41:50.622746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dcm_wrap = DCM_Wrapper(DCM_params)\n",
    "dsm_wrap = DSM_Wrapper(DSM_params)\n",
    "\n",
    "models_wrap = [\n",
    "    (\"DCM\", dcm_wrap),\n",
    "    (\"DSM\", dsm_wrap),\n",
    "]\n",
    "\n",
    "results = [benchmark_model(name, model_wrap, train_data, val_data, test_data)\n",
    "           for name, model_wrap in models_wrap]\n",
    "\n",
    "# save fitted model\n",
    "for name, model in models_wrap:\n",
    "    with open(f'{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model.model, f)\n",
    "\n",
    "pd.DataFrame(results)"
   ],
   "id": "e3b20988242e4980",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]D:\\anaconda3\\envs\\FLCausalMixture\\lib\\site-packages\\auton_survival\\models\\dcm\\dcm_utilities.py:105: RuntimeWarning: invalid value encountered in log\n",
      "  probs = gates+np.log(event_probs)\n",
      "  5%|▌         | 5/100 [00:01<00:32,  2.95it/s]D:\\anaconda3\\envs\\FLCausalMixture\\lib\\site-packages\\auton_survival\\models\\dcm\\dcm_utilities.py:105: RuntimeWarning: divide by zero encountered in log\n",
      "  probs = gates+np.log(event_probs)\n",
      " 11%|█         | 11/100 [00:03<00:30,  2.92it/s]D:\\anaconda3\\envs\\FLCausalMixture\\lib\\site-packages\\auton_survival\\models\\dcm\\dcm_utilities.py:58: RuntimeWarning: invalid value encountered in power\n",
      "  return spl(ts)**risks\n",
      "D:\\anaconda3\\envs\\FLCausalMixture\\lib\\site-packages\\auton_survival\\models\\dcm\\dcm_utilities.py:53: RuntimeWarning: invalid value encountered in power\n",
      "  s0ts = (-risks)*(spl(ts)**(risks-1))\n",
      " 48%|████▊     | 48/100 [00:17<00:18,  2.79it/s]\n",
      " 67%|██████▋   | 67/100 [00:31<00:15,  2.10it/s]\n",
      " 30%|███       | 30/100 [00:14<00:33,  2.11it/s]\n",
      " 61%|██████    | 61/100 [00:32<00:20,  1.89it/s]\n",
      " 34%|███▍      | 34/100 [00:16<00:31,  2.12it/s]\n",
      " 61%|██████    | 61/100 [00:27<00:17,  2.25it/s]\n",
      " 20%|██        | 20/100 [00:10<00:42,  1.89it/s]\n",
      " 38%|███▊      | 38/100 [00:19<00:31,  1.97it/s]\n",
      " 44%|████▍     | 44/100 [00:24<00:30,  1.83it/s]\n",
      " 56%|█████▌    | 56/100 [00:31<00:24,  1.77it/s]\n",
      " 19%|█▉        | 19/100 [00:11<00:49,  1.62it/s]\n",
      " 48%|████▊     | 48/100 [00:30<00:33,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete!\n",
      "Predict complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1797/10000 [00:03<00:16, 510.13it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.74it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 510.28it/s]\n",
      " 92%|█████████▏| 92/100 [00:12<00:01,  7.64it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 507.20it/s]\n",
      " 93%|█████████▎| 93/100 [00:13<00:01,  6.70it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 505.56it/s]\n",
      " 27%|██▋       | 27/100 [00:04<00:11,  6.46it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 512.86it/s]\n",
      " 67%|██████▋   | 67/100 [00:11<00:05,  6.08it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 506.66it/s]\n",
      " 23%|██▎       | 23/100 [00:04<00:13,  5.66it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 500.64it/s]\n",
      " 93%|█████████▎| 93/100 [00:14<00:01,  6.46it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 507.53it/s]\n",
      " 17%|█▋        | 17/100 [00:02<00:13,  6.03it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 512.42it/s]\n",
      " 60%|██████    | 60/100 [00:11<00:07,  5.22it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 511.88it/s]\n",
      "  9%|▉         | 9/100 [00:01<00:18,  4.91it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 507.14it/s]\n",
      "100%|██████████| 100/100 [00:14<00:00,  6.74it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 487.72it/s]\n",
      " 92%|█████████▏| 92/100 [00:13<00:01,  6.68it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 505.34it/s]\n",
      " 93%|█████████▎| 93/100 [00:15<00:01,  6.02it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 511.98it/s]\n",
      " 34%|███▍      | 34/100 [00:05<00:11,  5.83it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 508.36it/s]\n",
      " 67%|██████▋   | 67/100 [00:12<00:06,  5.47it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 509.18it/s]\n",
      " 17%|█▋        | 17/100 [00:03<00:16,  5.16it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 505.27it/s]\n",
      " 93%|█████████▎| 93/100 [00:16<00:01,  5.74it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 518.27it/s]\n",
      " 17%|█▋        | 17/100 [00:03<00:15,  5.33it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 516.70it/s]\n",
      " 36%|███▌      | 36/100 [00:07<00:13,  4.89it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 507.35it/s]\n",
      " 14%|█▍        | 14/100 [00:02<00:18,  4.72it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 502.51it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.75it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 510.72it/s]\n",
      " 92%|█████████▏| 92/100 [00:12<00:01,  7.61it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 505.46it/s]\n",
      " 93%|█████████▎| 93/100 [00:13<00:01,  6.70it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 512.12it/s]\n",
      " 27%|██▋       | 27/100 [00:04<00:11,  6.44it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 510.43it/s]\n",
      " 67%|██████▋   | 67/100 [00:11<00:05,  5.98it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 514.43it/s]\n",
      " 23%|██▎       | 23/100 [00:03<00:13,  5.91it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 510.76it/s]\n",
      " 93%|█████████▎| 93/100 [00:14<00:01,  6.42it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 516.95it/s]\n",
      " 17%|█▋        | 17/100 [00:02<00:14,  5.70it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 492.36it/s]\n",
      " 60%|██████    | 60/100 [00:10<00:07,  5.54it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 504.40it/s]\n",
      "  9%|▉         | 9/100 [00:01<00:18,  4.88it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 509.08it/s]\n",
      "100%|██████████| 100/100 [00:14<00:00,  6.80it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 518.20it/s]\n",
      " 92%|█████████▏| 92/100 [00:13<00:01,  6.76it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 513.04it/s]\n",
      " 93%|█████████▎| 93/100 [00:15<00:01,  5.84it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 513.43it/s]\n",
      " 34%|███▍      | 34/100 [00:05<00:11,  5.88it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 507.09it/s]\n",
      " 67%|██████▋   | 67/100 [00:12<00:05,  5.52it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 513.92it/s]\n",
      " 17%|█▋        | 17/100 [00:03<00:15,  5.29it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 518.13it/s]\n",
      " 93%|█████████▎| 93/100 [00:16<00:01,  5.81it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 508.84it/s]\n",
      " 17%|█▋        | 17/100 [00:03<00:16,  5.14it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:16, 512.32it/s]\n",
      " 36%|███▌      | 36/100 [00:07<00:12,  5.02it/s]\n",
      " 18%|█▊        | 1797/10000 [00:03<00:15, 515.24it/s]\n",
      " 14%|█▍        | 14/100 [00:02<00:17,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete!\n",
      "Predict complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Model  Train Time  Predict Time  0.25 quantile TD Concordance Index  \\\n",
       "0   DCM  266.639422      0.000998                            0.771127   \n",
       "1   DSM  509.018910      0.005984                            0.235730   \n",
       "\n",
       "   0.25 quantile Brier Score  0.25 quantile ROC AUC  \\\n",
       "0                   0.108708               0.781708   \n",
       "1                   0.107729               0.227737   \n",
       "\n",
       "   0.5 quantile TD Concordance Index  0.5 quantile Brier Score  \\\n",
       "0                           0.717221                  0.178909   \n",
       "1                           0.298051                  0.178950   \n",
       "\n",
       "   0.5 quantile ROC AUC  0.75 quantile TD Concordance Index  \\\n",
       "0              0.741438                            0.673002   \n",
       "1              0.274391                            0.330637   \n",
       "\n",
       "   0.75 quantile Brier Score  0.75 quantile ROC AUC  \n",
       "0                   0.220844               0.716491  \n",
       "1                   0.215506               0.285361  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Predict Time</th>\n",
       "      <th>0.25 quantile TD Concordance Index</th>\n",
       "      <th>0.25 quantile Brier Score</th>\n",
       "      <th>0.25 quantile ROC AUC</th>\n",
       "      <th>0.5 quantile TD Concordance Index</th>\n",
       "      <th>0.5 quantile Brier Score</th>\n",
       "      <th>0.5 quantile ROC AUC</th>\n",
       "      <th>0.75 quantile TD Concordance Index</th>\n",
       "      <th>0.75 quantile Brier Score</th>\n",
       "      <th>0.75 quantile ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DCM</td>\n",
       "      <td>266.639422</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.771127</td>\n",
       "      <td>0.108708</td>\n",
       "      <td>0.781708</td>\n",
       "      <td>0.717221</td>\n",
       "      <td>0.178909</td>\n",
       "      <td>0.741438</td>\n",
       "      <td>0.673002</td>\n",
       "      <td>0.220844</td>\n",
       "      <td>0.716491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSM</td>\n",
       "      <td>509.018910</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.235730</td>\n",
       "      <td>0.107729</td>\n",
       "      <td>0.227737</td>\n",
       "      <td>0.298051</td>\n",
       "      <td>0.178950</td>\n",
       "      <td>0.274391</td>\n",
       "      <td>0.330637</td>\n",
       "      <td>0.215506</td>\n",
       "      <td>0.285361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLCausalMixture",
   "language": "python",
   "name": "flcausalmixture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
